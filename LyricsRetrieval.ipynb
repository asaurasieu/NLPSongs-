{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in /Users/anita/.pyenv/versions/3.9.7/lib/python3.9/site-packages (2.6.1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.32.0 in /Users/anita/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from sentence-transformers) (4.39.2)\n",
      "Requirement already satisfied: tqdm in /Users/anita/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from sentence-transformers) (4.66.2)\n",
      "Requirement already satisfied: torch>=1.11.0 in /Users/anita/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from sentence-transformers) (2.2.1)\n",
      "Requirement already satisfied: numpy in /Users/anita/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from sentence-transformers) (1.26.4)\n",
      "Requirement already satisfied: scikit-learn in /Users/anita/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from sentence-transformers) (1.1.3)\n",
      "Requirement already satisfied: scipy in /Users/anita/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from sentence-transformers) (1.12.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.15.1 in /Users/anita/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from sentence-transformers) (0.21.4)\n",
      "Requirement already satisfied: Pillow in /Users/anita/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from sentence-transformers) (10.3.0)\n",
      "Requirement already satisfied: filelock in /Users/anita/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/anita/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2024.2.0)\n",
      "Requirement already satisfied: requests in /Users/anita/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.31.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/anita/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/anita/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.10.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/anita/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (23.2)\n",
      "Requirement already satisfied: sympy in /Users/anita/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from torch>=1.11.0->sentence-transformers) (1.12)\n",
      "Requirement already satisfied: networkx in /Users/anita/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from torch>=1.11.0->sentence-transformers) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /Users/anita/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/anita/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (2023.12.25)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /Users/anita/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/anita/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (0.4.2)\n",
      "Requirement already satisfied: joblib>=1.0.0 in /Users/anita/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from scikit-learn->sentence-transformers) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/anita/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from scikit-learn->sentence-transformers) (3.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/anita/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/anita/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/anita/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/anita/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/anita/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/anita/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: lyricsgenius in /Users/anita/.pyenv/versions/3.9.7/lib/python3.9/site-packages (3.0.1)\n",
      "Requirement already satisfied: beautifulsoup4>=4.6.0 in /Users/anita/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from lyricsgenius) (4.9.3)\n",
      "Requirement already satisfied: requests>=2.20.0 in /Users/anita/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from lyricsgenius) (2.31.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/anita/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from beautifulsoup4>=4.6.0->lyricsgenius) (2.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/anita/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from requests>=2.20.0->lyricsgenius) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/anita/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from requests>=2.20.0->lyricsgenius) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/anita/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from requests>=2.20.0->lyricsgenius) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/anita/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from requests>=2.20.0->lyricsgenius) (2024.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install -U sentence-transformers\n",
    "!pip3 install lyricsgenius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/anita/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/anita/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Imports and setup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import requests\n",
    "import lyricsgenius\n",
    "import dotenv \n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd\n",
    "import logging\n",
    "from langdetect import detect\n",
    "import re\n",
    "import nltk\n",
    "import pickle\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the fine-tuned BERT model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility Functions\n",
    "mean pooling, preprocessing lyrics, and encoding lyrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions\n",
    "# Expanding Contractions\n",
    "CONTRACTION_MAP = {\n",
    "    \"can't\": \"cannot\",\n",
    "    \"won't\": \"will not\",\n",
    "    \"n't\": \" not\",\n",
    "    \"'re\": \" are\",\n",
    "    \"'s\": \" is\",\n",
    "    \"'m\": \" am\",\n",
    "    \"'ll\": \" will\",\n",
    "    \"'d\": \" would\",\n",
    "    \"'ve\": \" have\",\n",
    "    \"o'clock\": \"of the clock\",\n",
    "    \"ma'am\": \"madam\",\n",
    "    \"let's\": \"let us\"\n",
    "}\n",
    "\n",
    "def expand_contractions(lyrics, contraction_mapping=CONTRACTION_MAP):\n",
    "    contractions_pattern = re.compile('({})'.format('|'.join(contraction_mapping.keys())), flags=re.IGNORECASE|re.DOTALL)\n",
    "    def expand_match(contraction):\n",
    "        match = contraction.group(0)\n",
    "        first_char = match[0]\n",
    "        expanded_contraction = contraction_mapping.get(match.lower() if match.lower() in contraction_mapping else match)\n",
    "        return first_char + expanded_contraction[1:]\n",
    "    expanded_lyrics = contractions_pattern.sub(expand_match, lyrics)\n",
    "    return expanded_lyrics\n",
    "\n",
    "def preprocess_lyrics(lyrics):\n",
    "    lyrics = expand_contractions(lyrics)  # Make sure to use 'lyrics' not 'text'\n",
    "    lyrics = re.sub(r'\\[(.*?)\\]', '', lyrics)  # remove [Verse], [Chorus] tags\n",
    "    lyrics = lyrics.lower()  # lowercase\n",
    "    tokens = word_tokenize(lyrics)  # tokenize\n",
    "    return ' '.join(tokens)  # Return the processed lyrics as a single string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess and Encode Lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Starting to read CSV file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Finished reading CSV file. DataFrame shape: (3744, 5)\n",
      "INFO:root:Starting to preprocess lyrics\n",
      "INFO:root:Finished preprocessing lyrics\n"
     ]
    }
   ],
   "source": [
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "logging.info(\"Starting to read CSV file\")\n",
    "df = pd.read_csv('music_data.csv')  \n",
    "logging.info(f\"Finished reading CSV file. DataFrame shape: {df.shape}\")\n",
    "\n",
    "logging.info(\"Starting to preprocess lyrics\")\n",
    "df['preprocessed_lyrics'] = df['lyrics'].apply(preprocess_lyrics)\n",
    "logging.info(\"Finished preprocessing lyrics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lyrics</th>\n",
       "      <th>preprocessed_lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Verse 1]\\nThought I'd end up with Sean\\nBut h...</td>\n",
       "      <td>thought i'would end up with sean but he wasnno...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Verse 1]\\nYeah, breakfast at Tiffany's and bo...</td>\n",
       "      <td>yeah , breakfast at tiffany'is and bottles of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Chorus]\\nYou, you love it how I move you\\nYou...</td>\n",
       "      <td>you , you love it how i move you you love it h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Intro: Ariana Grande &amp; Nicki Minaj]\\nI've bee...</td>\n",
       "      <td>i'have been here all night ( ariana ) i'have b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Intro]\\nRight now, I'm in a state of mind\\nI ...</td>\n",
       "      <td>right now , i'am in a state of mind i wan na b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[Intro]\\n​​lacigam gnihtemos od oT\\n​​thgin la...</td>\n",
       "      <td>​​lacigam gnihtemos od ot ​​thgin laiceps ruoy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[Verse 1]\\nYou got me some type of way (Hmm)\\n...</td>\n",
       "      <td>you got me some type of way ( hmm ) ainnot use...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[Verse 1]\\nHeaven sent you to me\\nI'm just hop...</td>\n",
       "      <td>heaven sent you to me i'am just hopin ’ i donn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[Intro]\\nHmm\\n\\n[Verse 1]\\nYou might think I'm...</td>\n",
       "      <td>hmm you might think i'am crazy the way i'have ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[Verse 1]\\nStep up, the two of us, nobody know...</td>\n",
       "      <td>step up , the two of us , nobody knows us get ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              lyrics  \\\n",
       "0  [Verse 1]\\nThought I'd end up with Sean\\nBut h...   \n",
       "1  [Verse 1]\\nYeah, breakfast at Tiffany's and bo...   \n",
       "2  [Chorus]\\nYou, you love it how I move you\\nYou...   \n",
       "3  [Intro: Ariana Grande & Nicki Minaj]\\nI've bee...   \n",
       "4  [Intro]\\nRight now, I'm in a state of mind\\nI ...   \n",
       "5  [Intro]\\n​​lacigam gnihtemos od oT\\n​​thgin la...   \n",
       "6  [Verse 1]\\nYou got me some type of way (Hmm)\\n...   \n",
       "7  [Verse 1]\\nHeaven sent you to me\\nI'm just hop...   \n",
       "8  [Intro]\\nHmm\\n\\n[Verse 1]\\nYou might think I'm...   \n",
       "9  [Verse 1]\\nStep up, the two of us, nobody know...   \n",
       "\n",
       "                                 preprocessed_lyrics  \n",
       "0  thought i'would end up with sean but he wasnno...  \n",
       "1  yeah , breakfast at tiffany'is and bottles of ...  \n",
       "2  you , you love it how i move you you love it h...  \n",
       "3  i'have been here all night ( ariana ) i'have b...  \n",
       "4  right now , i'am in a state of mind i wan na b...  \n",
       "5  ​​lacigam gnihtemos od ot ​​thgin laiceps ruoy...  \n",
       "6  you got me some type of way ( hmm ) ainnot use...  \n",
       "7  heaven sent you to me i'am just hopin ’ i donn...  \n",
       "8  hmm you might think i'am crazy the way i'have ...  \n",
       "9  step up , the two of us , nobody knows us get ...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['lyrics', 'preprocessed_lyrics']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Starting to get embeddings\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ea87e4a40a64017a9e35fc2ad1c136f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/117 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Finished getting embeddings\n"
     ]
    }
   ],
   "source": [
    "logging.info(\"Starting to get embeddings\")\n",
    "df['embeddings'] = list(model.encode(df['lyrics'].tolist(), show_progress_bar=True))\n",
    "logging.info(\"Finished getting embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>preprocessed_lyrics</th>\n",
       "      <th>embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ariana Grande</td>\n",
       "      <td>thought i'would end up with sean but he wasnno...</td>\n",
       "      <td>[-0.07796759, -0.047370087, 0.06382991, -0.046...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ariana Grande</td>\n",
       "      <td>yeah , breakfast at tiffany'is and bottles of ...</td>\n",
       "      <td>[-0.09182351, 0.038527973, 0.051597822, -0.053...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ariana Grande</td>\n",
       "      <td>you , you love it how i move you you love it h...</td>\n",
       "      <td>[-0.035600673, -0.045947228, 0.06202742, -0.04...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ariana Grande</td>\n",
       "      <td>i'have been here all night ( ariana ) i'have b...</td>\n",
       "      <td>[-0.04670759, -0.03384533, 0.02231615, -0.0330...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ariana Grande</td>\n",
       "      <td>right now , i'am in a state of mind i wan na b...</td>\n",
       "      <td>[-0.09957284, -0.02273628, 0.07063174, -0.0655...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ariana Grande</td>\n",
       "      <td>​​lacigam gnihtemos od ot ​​thgin laiceps ruoy...</td>\n",
       "      <td>[-0.044333555, -0.046792664, 0.071543686, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ariana Grande</td>\n",
       "      <td>you got me some type of way ( hmm ) ainnot use...</td>\n",
       "      <td>[-0.058477826, -0.049745448, 0.07734181, -0.04...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Ariana Grande</td>\n",
       "      <td>heaven sent you to me i'am just hopin ’ i donn...</td>\n",
       "      <td>[-0.060370278, -0.05460217, 0.071599156, -0.04...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ariana Grande</td>\n",
       "      <td>hmm you might think i'am crazy the way i'have ...</td>\n",
       "      <td>[-0.09731813, -0.04326297, 0.026763892, -0.005...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ariana Grande</td>\n",
       "      <td>step up , the two of us , nobody knows us get ...</td>\n",
       "      <td>[-0.10925642, -0.04081988, 0.06588498, 0.00217...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          artist                                preprocessed_lyrics  \\\n",
       "0  Ariana Grande  thought i'would end up with sean but he wasnno...   \n",
       "1  Ariana Grande  yeah , breakfast at tiffany'is and bottles of ...   \n",
       "2  Ariana Grande  you , you love it how i move you you love it h...   \n",
       "3  Ariana Grande  i'have been here all night ( ariana ) i'have b...   \n",
       "4  Ariana Grande  right now , i'am in a state of mind i wan na b...   \n",
       "5  Ariana Grande  ​​lacigam gnihtemos od ot ​​thgin laiceps ruoy...   \n",
       "6  Ariana Grande  you got me some type of way ( hmm ) ainnot use...   \n",
       "7  Ariana Grande  heaven sent you to me i'am just hopin ’ i donn...   \n",
       "8  Ariana Grande  hmm you might think i'am crazy the way i'have ...   \n",
       "9  Ariana Grande  step up , the two of us , nobody knows us get ...   \n",
       "\n",
       "                                          embeddings  \n",
       "0  [-0.07796759, -0.047370087, 0.06382991, -0.046...  \n",
       "1  [-0.09182351, 0.038527973, 0.051597822, -0.053...  \n",
       "2  [-0.035600673, -0.045947228, 0.06202742, -0.04...  \n",
       "3  [-0.04670759, -0.03384533, 0.02231615, -0.0330...  \n",
       "4  [-0.09957284, -0.02273628, 0.07063174, -0.0655...  \n",
       "5  [-0.044333555, -0.046792664, 0.071543686, -0.0...  \n",
       "6  [-0.058477826, -0.049745448, 0.07734181, -0.04...  \n",
       "7  [-0.060370278, -0.05460217, 0.071599156, -0.04...  \n",
       "8  [-0.09731813, -0.04326297, 0.026763892, -0.005...  \n",
       "9  [-0.10925642, -0.04081988, 0.06588498, 0.00217...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['artist', 'preprocessed_lyrics', 'embeddings']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_lyrics_sentence_transformer(query, df, model):\n",
    "    # Encode the query to get the embedding\n",
    "    query_embedding = model.encode([query])[0]  \n",
    "    # Calculate cosine similarities between the query and all lyrics embeddings\n",
    "    similarities = cosine_similarity([query_embedding], df['embeddings'].tolist()).flatten()\n",
    "    # Get indices of the songs with the highest similarity scores\n",
    "    top_indices = similarities.argsort()[-5:][::-1]\n",
    "    return df.iloc[top_indices]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abaccaaf57514e24b73c384a92b50c9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            artist                     title\n",
      "732       Coldplay              Up in Flames\n",
      "3415  Taylor Swift               Blank Space\n",
      "818       Coldplay              Ring of Fire\n",
      "990          Drake                 Fireworks\n",
      "2225    Katy Perry  Not the End of the World\n"
     ]
    }
   ],
   "source": [
    "query = \"so it's gonna be forever or it's gonna go down in flames\"\n",
    "results = search_lyrics_sentence_transformer(query, df, model)\n",
    "print(results[['artist', 'title']])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
