{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in /Users/anita/.pyenv/versions/3.9.7/lib/python3.9/site-packages (2.6.1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.32.0 in /Users/anita/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from sentence-transformers) (4.39.2)\n",
      "Requirement already satisfied: tqdm in /Users/anita/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from sentence-transformers) (4.66.2)\n",
      "Requirement already satisfied: torch>=1.11.0 in /Users/anita/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from sentence-transformers) (2.2.1)\n",
      "Requirement already satisfied: numpy in /Users/anita/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from sentence-transformers) (1.26.4)\n",
      "Requirement already satisfied: scikit-learn in /Users/anita/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from sentence-transformers) (1.1.3)\n",
      "Requirement already satisfied: scipy in /Users/anita/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from sentence-transformers) (1.12.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.15.1 in /Users/anita/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from sentence-transformers) (0.21.4)\n",
      "Requirement already satisfied: Pillow in /Users/anita/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from sentence-transformers) (10.3.0)\n",
      "Requirement already satisfied: filelock in /Users/anita/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/anita/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2024.2.0)\n",
      "Requirement already satisfied: requests in /Users/anita/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.31.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/anita/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/anita/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.10.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/anita/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (23.2)\n",
      "Requirement already satisfied: sympy in /Users/anita/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from torch>=1.11.0->sentence-transformers) (1.12)\n",
      "Requirement already satisfied: networkx in /Users/anita/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from torch>=1.11.0->sentence-transformers) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /Users/anita/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/anita/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (2023.12.25)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /Users/anita/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/anita/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (0.4.2)\n",
      "Requirement already satisfied: joblib>=1.0.0 in /Users/anita/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from scikit-learn->sentence-transformers) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/anita/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from scikit-learn->sentence-transformers) (3.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/anita/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/anita/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/anita/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/anita/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/anita/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/anita/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: lyricsgenius in /Users/anita/.pyenv/versions/3.9.7/lib/python3.9/site-packages (3.0.1)\n",
      "Requirement already satisfied: beautifulsoup4>=4.6.0 in /Users/anita/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from lyricsgenius) (4.9.3)\n",
      "Requirement already satisfied: requests>=2.20.0 in /Users/anita/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from lyricsgenius) (2.31.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/anita/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from beautifulsoup4>=4.6.0->lyricsgenius) (2.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/anita/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from requests>=2.20.0->lyricsgenius) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/anita/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from requests>=2.20.0->lyricsgenius) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/anita/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from requests>=2.20.0->lyricsgenius) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/anita/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from requests>=2.20.0->lyricsgenius) (2024.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install -U sentence-transformers\n",
    "!pip3 install lyricsgenius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/anita/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/anita/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Imports and setup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import requests\n",
    "import lyricsgenius\n",
    "import dotenv \n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd\n",
    "import logging\n",
    "from langdetect import detect\n",
    "import re\n",
    "import nltk\n",
    "import pickle\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the fine-tuned BERT model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully!\n",
      "Sample data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>title</th>\n",
       "      <th>id</th>\n",
       "      <th>release_date</th>\n",
       "      <th>lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ariana Grande</td>\n",
       "      <td>â€‹thank u, next</td>\n",
       "      <td>4063065</td>\n",
       "      <td>2018-11-03</td>\n",
       "      <td>[Verse 1]\\nThought I'd end up with Sean\\nBut h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ariana Grande</td>\n",
       "      <td>7 rings</td>\n",
       "      <td>4067762</td>\n",
       "      <td>2019-01-18</td>\n",
       "      <td>[Verse 1]\\nYeah, breakfast at Tiffany's and bo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ariana Grande</td>\n",
       "      <td>â€‹God is a woman</td>\n",
       "      <td>3681280</td>\n",
       "      <td>2018-07-13</td>\n",
       "      <td>[Chorus]\\nYou, you love it how I move you\\nYou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ariana Grande</td>\n",
       "      <td>Side To Side</td>\n",
       "      <td>2457495</td>\n",
       "      <td>2016-05-20</td>\n",
       "      <td>[Intro: Ariana Grande &amp; Nicki Minaj]\\nI've bee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ariana Grande</td>\n",
       "      <td>â€‹â€‹no tears left to cry</td>\n",
       "      <td>3649172</td>\n",
       "      <td>2018-04-20</td>\n",
       "      <td>[Intro]\\nRight now, I'm in a state of mind\\nI ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3739</th>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>Taylor Swift - no body, no crime (TraducciÃ³n a...</td>\n",
       "      <td>6274728</td>\n",
       "      <td>2020-12-11</td>\n",
       "      <td>[Intro: HAIM]\\nÃ‰l lo hizo\\nÃ‰l lo hizo\\n\\n[Vers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3740</th>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>Welcome Back Grunwald</td>\n",
       "      <td>6226864</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Turn WYCD on\\nYou're\\nOn your Grunwald\\nBack f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3741</th>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>Tolerate it (Polskie TÅ‚umaczenie)</td>\n",
       "      <td>6315848</td>\n",
       "      <td>2020-12-11</td>\n",
       "      <td>[Zwrotka 1]\\nSiedzÄ™ i patrzÄ™ jak czytasz z gÅ‚o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3742</th>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>Find you</td>\n",
       "      <td>6209316</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Trying just like they say\\nJust taking the ste...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3743</th>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>Clean - TÃ¼rkÃ§e Ã‡eviri</td>\n",
       "      <td>6387638</td>\n",
       "      <td>2014-10-27</td>\n",
       "      <td>[Verse 1]\\nKuraklÄ±k en kÃ¶tÃ¼sÃ¼ydÃ¼(Oh-oh-oh)\\nBe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3744 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             artist                                              title  \\\n",
       "0     Ariana Grande                                     â€‹thank u, next   \n",
       "1     Ariana Grande                                            7 rings   \n",
       "2     Ariana Grande                                    â€‹God is a woman   \n",
       "3     Ariana Grande                                       Side To Side   \n",
       "4     Ariana Grande                             â€‹â€‹no tears left to cry   \n",
       "...             ...                                                ...   \n",
       "3739   Taylor Swift  Taylor Swift - no body, no crime (TraducciÃ³n a...   \n",
       "3740   Taylor Swift                              Welcome Back Grunwald   \n",
       "3741   Taylor Swift                  Tolerate it (Polskie TÅ‚umaczenie)   \n",
       "3742   Taylor Swift                                           Find you   \n",
       "3743   Taylor Swift                              Clean - TÃ¼rkÃ§e Ã‡eviri   \n",
       "\n",
       "           id release_date                                             lyrics  \n",
       "0     4063065   2018-11-03  [Verse 1]\\nThought I'd end up with Sean\\nBut h...  \n",
       "1     4067762   2019-01-18  [Verse 1]\\nYeah, breakfast at Tiffany's and bo...  \n",
       "2     3681280   2018-07-13  [Chorus]\\nYou, you love it how I move you\\nYou...  \n",
       "3     2457495   2016-05-20  [Intro: Ariana Grande & Nicki Minaj]\\nI've bee...  \n",
       "4     3649172   2018-04-20  [Intro]\\nRight now, I'm in a state of mind\\nI ...  \n",
       "...       ...          ...                                                ...  \n",
       "3739  6274728   2020-12-11  [Intro: HAIM]\\nÃ‰l lo hizo\\nÃ‰l lo hizo\\n\\n[Vers...  \n",
       "3740  6226864          NaN  Turn WYCD on\\nYou're\\nOn your Grunwald\\nBack f...  \n",
       "3741  6315848   2020-12-11  [Zwrotka 1]\\nSiedzÄ™ i patrzÄ™ jak czytasz z gÅ‚o...  \n",
       "3742  6209316          NaN  Trying just like they say\\nJust taking the ste...  \n",
       "3743  6387638   2014-10-27  [Verse 1]\\nKuraklÄ±k en kÃ¶tÃ¼sÃ¼ydÃ¼(Oh-oh-oh)\\nBe...  \n",
       "\n",
       "[3744 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('music_data.csv')  \n",
    "print(\"Data loaded successfully!\")\n",
    "print(\"Sample data:\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "artist            0\n",
      "title             0\n",
      "id                0\n",
      "release_date    993\n",
      "lyrics            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "null_values = df.isnull().sum()\n",
    "print(null_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove null values\n",
    "df= df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "duplicate_rows = df.duplicated().sum()\n",
    "print(duplicate_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langdetect import detect\n",
    "\n",
    "def is_english(row):\n",
    "    for column in row:\n",
    "        try:\n",
    "            if detect(str(column)) != 'en':\n",
    "                return False\n",
    "        except:\n",
    "            pass\n",
    "    return True\n",
    "\n",
    "mask = df.apply(is_english, axis=1)\n",
    "df = df[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered and cleaned data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>title</th>\n",
       "      <th>id</th>\n",
       "      <th>release_date</th>\n",
       "      <th>lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>517</th>\n",
       "      <td>Charlie Puth</td>\n",
       "      <td>We Donâ€™t Talk Anymore</td>\n",
       "      <td>2388373</td>\n",
       "      <td>2016-05-24</td>\n",
       "      <td>[Chorus: Charlie Puth]\\nWe don't talk anymore,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>Charlie Puth</td>\n",
       "      <td>How Long</td>\n",
       "      <td>3236636</td>\n",
       "      <td>2017-10-05</td>\n",
       "      <td>[Intro]\\nAlright\\nOoh, yeah\\n\\n[Verse 1]\\nI'll...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>Charlie Puth</td>\n",
       "      <td>Marvin Gaye</td>\n",
       "      <td>706298</td>\n",
       "      <td>2015-02-10</td>\n",
       "      <td>[Intro: Charlie Puth]\\nLet's Marvin Gaye and g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>Charlie Puth</td>\n",
       "      <td>One Call Away</td>\n",
       "      <td>2276633</td>\n",
       "      <td>2015-08-20</td>\n",
       "      <td>[Chorus]\\nI'm only one call away\\nI'll be ther...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>Charlie Puth</td>\n",
       "      <td>The Way I Am</td>\n",
       "      <td>3598344</td>\n",
       "      <td>2018-05-03</td>\n",
       "      <td>[Verse 1]\\nYeah, maybe I'ma get a little anxio...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           artist                  title       id release_date  \\\n",
       "517  Charlie Puth  We Donâ€™t Talk Anymore  2388373   2016-05-24   \n",
       "518  Charlie Puth               How Long  3236636   2017-10-05   \n",
       "519  Charlie Puth            Marvin Gaye   706298   2015-02-10   \n",
       "520  Charlie Puth          One Call Away  2276633   2015-08-20   \n",
       "522  Charlie Puth           The Way I Am  3598344   2018-05-03   \n",
       "\n",
       "                                                lyrics  \n",
       "517  [Chorus: Charlie Puth]\\nWe don't talk anymore,...  \n",
       "518  [Intro]\\nAlright\\nOoh, yeah\\n\\n[Verse 1]\\nI'll...  \n",
       "519  [Intro: Charlie Puth]\\nLet's Marvin Gaye and g...  \n",
       "520  [Chorus]\\nI'm only one call away\\nI'll be ther...  \n",
       "522  [Verse 1]\\nYeah, maybe I'ma get a little anxio...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Filtered and cleaned data:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions\n",
    "# Expanding Contractions\n",
    "CONTRACTION_MAP = {\n",
    "    \"can't\": \"cannot\",\n",
    "    \"won't\": \"will not\",\n",
    "    \"n't\": \" not\",\n",
    "    \"'re\": \" are\",\n",
    "    \"'s\": \" is\",\n",
    "    \"'m\": \" am\",\n",
    "    \"'ll\": \" will\",\n",
    "    \"'d\": \" would\",\n",
    "    \"'ve\": \" have\",\n",
    "    \"o'clock\": \"of the clock\",\n",
    "    \"ma'am\": \"madam\",\n",
    "    \"let's\": \"let us\"\n",
    "}\n",
    "\n",
    "def expand_contractions(lyrics, contraction_mapping=CONTRACTION_MAP):\n",
    "    contractions_pattern = re.compile('({})'.format('|'.join(contraction_mapping.keys())), flags=re.IGNORECASE|re.DOTALL)\n",
    "    def expand_match(contraction):\n",
    "        match = contraction.group(0)\n",
    "        first_char = match[0]\n",
    "        expanded_contraction = contraction_mapping.get(match.lower() if match.lower() in contraction_mapping else match)\n",
    "        return first_char + expanded_contraction[1:]\n",
    "    expanded_lyrics = contractions_pattern.sub(expand_match, lyrics)\n",
    "    return expanded_lyrics\n",
    "\n",
    "def preprocess_lyrics(lyrics):\n",
    "    lyrics = expand_contractions(lyrics)  # Make sure to use 'lyrics' not 'text'\n",
    "    lyrics = re.sub(r'\\[(.*?)\\]', '', lyrics)  # remove [Verse], [Chorus] tags\n",
    "    lyrics = lyrics.lower()  # lowercase\n",
    "    tokens = word_tokenize(lyrics)  # tokenize\n",
    "    return ' '.join(tokens)  # Return the processed lyrics as a single string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encode Lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Starting to preprocess lyrics\n",
      "INFO:root:Finished preprocessing lyrics\n"
     ]
    }
   ],
   "source": [
    "logging.basicConfig(level=logging.INFO)\n",
    "logging.info(\"Starting to preprocess lyrics\")\n",
    "df['preprocessed_lyrics'] = df['lyrics'].apply(preprocess_lyrics)\n",
    "logging.info(\"Finished preprocessing lyrics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lyrics</th>\n",
       "      <th>preprocessed_lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>517</th>\n",
       "      <td>[Chorus: Charlie Puth]\\nWe don't talk anymore,...</td>\n",
       "      <td>we donnot talk anymore , we donnot talk anymor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>[Intro]\\nAlright\\nOoh, yeah\\n\\n[Verse 1]\\nI'll...</td>\n",
       "      <td>alright ooh , yeah i'will admit , i was wrong ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>[Intro: Charlie Puth]\\nLet's Marvin Gaye and g...</td>\n",
       "      <td>let us marvin gaye and get it on you got the h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>[Chorus]\\nI'm only one call away\\nI'll be ther...</td>\n",
       "      <td>i'am only one call away i'will be there to sav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>[Verse 1]\\nYeah, maybe I'ma get a little anxio...</td>\n",
       "      <td>yeah , maybe i'ama get a little anxious maybe ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523</th>\n",
       "      <td>[Verse 1: Charlie Puth]\\nNo, this is not goodb...</td>\n",
       "      <td>no , this is not goodbye i swear that i'am gon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526</th>\n",
       "      <td>[Verse 1]\\nIt started with a kiss\\nOn your mam...</td>\n",
       "      <td>it started with a kiss on your mama'is couch 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>528</th>\n",
       "      <td>[Chorus]\\nI warned myself that I shouldn't pla...</td>\n",
       "      <td>i warned myself that i shouldnnot play with fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>[Verse 1]\\nHe's such a nice boy, so well-manne...</td>\n",
       "      <td>he'is such a nice boy , so well-mannered he'is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>[Chorus]\\nDon't run from me, river\\nDon't run ...</td>\n",
       "      <td>donnot run from me , river donnot run from me ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                lyrics  \\\n",
       "517  [Chorus: Charlie Puth]\\nWe don't talk anymore,...   \n",
       "518  [Intro]\\nAlright\\nOoh, yeah\\n\\n[Verse 1]\\nI'll...   \n",
       "519  [Intro: Charlie Puth]\\nLet's Marvin Gaye and g...   \n",
       "520  [Chorus]\\nI'm only one call away\\nI'll be ther...   \n",
       "522  [Verse 1]\\nYeah, maybe I'ma get a little anxio...   \n",
       "523  [Verse 1: Charlie Puth]\\nNo, this is not goodb...   \n",
       "526  [Verse 1]\\nIt started with a kiss\\nOn your mam...   \n",
       "528  [Chorus]\\nI warned myself that I shouldn't pla...   \n",
       "531  [Verse 1]\\nHe's such a nice boy, so well-manne...   \n",
       "533  [Chorus]\\nDon't run from me, river\\nDon't run ...   \n",
       "\n",
       "                                   preprocessed_lyrics  \n",
       "517  we donnot talk anymore , we donnot talk anymor...  \n",
       "518  alright ooh , yeah i'will admit , i was wrong ...  \n",
       "519  let us marvin gaye and get it on you got the h...  \n",
       "520  i'am only one call away i'will be there to sav...  \n",
       "522  yeah , maybe i'ama get a little anxious maybe ...  \n",
       "523  no , this is not goodbye i swear that i'am gon...  \n",
       "526  it started with a kiss on your mama'is couch 2...  \n",
       "528  i warned myself that i shouldnnot play with fi...  \n",
       "531  he'is such a nice boy , so well-mannered he'is...  \n",
       "533  donnot run from me , river donnot run from me ...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['lyrics', 'preprocessed_lyrics']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Starting to get embeddings\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d836998bcdc4a5db91413fdf161c4c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Finished getting embeddings\n"
     ]
    }
   ],
   "source": [
    "logging.info(\"Starting to get embeddings\")\n",
    "df['embeddings'] = list(model.encode(df['lyrics'].tolist(), show_progress_bar=True))\n",
    "logging.info(\"Finished getting embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>preprocessed_lyrics</th>\n",
       "      <th>embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>517</th>\n",
       "      <td>Charlie Puth</td>\n",
       "      <td>we donnot talk anymore , we donnot talk anymor...</td>\n",
       "      <td>[-0.06933179, -0.05280156, 0.096682414, -0.032...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>Charlie Puth</td>\n",
       "      <td>alright ooh , yeah i'will admit , i was wrong ...</td>\n",
       "      <td>[-0.08532193, -0.07560885, 0.11776075, 0.01836...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>Charlie Puth</td>\n",
       "      <td>let us marvin gaye and get it on you got the h...</td>\n",
       "      <td>[-0.12914756, -0.023826854, 0.03429907, -0.005...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>Charlie Puth</td>\n",
       "      <td>i'am only one call away i'will be there to sav...</td>\n",
       "      <td>[-0.08759198, -0.020269403, -0.0022983477, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>Charlie Puth</td>\n",
       "      <td>yeah , maybe i'ama get a little anxious maybe ...</td>\n",
       "      <td>[-0.023337308, -0.021497937, 0.1249926, -0.014...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523</th>\n",
       "      <td>Charlie Puth</td>\n",
       "      <td>no , this is not goodbye i swear that i'am gon...</td>\n",
       "      <td>[-0.020676365, -0.031019937, 0.101447135, 0.03...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526</th>\n",
       "      <td>Charlie Puth</td>\n",
       "      <td>it started with a kiss on your mama'is couch 2...</td>\n",
       "      <td>[-0.07356925, -0.06716579, 0.0592213, 0.053288...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>528</th>\n",
       "      <td>Charlie Puth</td>\n",
       "      <td>i warned myself that i shouldnnot play with fi...</td>\n",
       "      <td>[0.014884363, 0.018558545, 0.037044585, 0.0125...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>Charlie Puth</td>\n",
       "      <td>he'is such a nice boy , so well-mannered he'is...</td>\n",
       "      <td>[-0.035937082, 0.032252643, 0.039746188, 0.013...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>Charlie Puth</td>\n",
       "      <td>donnot run from me , river donnot run from me ...</td>\n",
       "      <td>[-0.019787563, -0.02365343, 0.11032831, -0.043...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           artist                                preprocessed_lyrics  \\\n",
       "517  Charlie Puth  we donnot talk anymore , we donnot talk anymor...   \n",
       "518  Charlie Puth  alright ooh , yeah i'will admit , i was wrong ...   \n",
       "519  Charlie Puth  let us marvin gaye and get it on you got the h...   \n",
       "520  Charlie Puth  i'am only one call away i'will be there to sav...   \n",
       "522  Charlie Puth  yeah , maybe i'ama get a little anxious maybe ...   \n",
       "523  Charlie Puth  no , this is not goodbye i swear that i'am gon...   \n",
       "526  Charlie Puth  it started with a kiss on your mama'is couch 2...   \n",
       "528  Charlie Puth  i warned myself that i shouldnnot play with fi...   \n",
       "531  Charlie Puth  he'is such a nice boy , so well-mannered he'is...   \n",
       "533  Charlie Puth  donnot run from me , river donnot run from me ...   \n",
       "\n",
       "                                            embeddings  \n",
       "517  [-0.06933179, -0.05280156, 0.096682414, -0.032...  \n",
       "518  [-0.08532193, -0.07560885, 0.11776075, 0.01836...  \n",
       "519  [-0.12914756, -0.023826854, 0.03429907, -0.005...  \n",
       "520  [-0.08759198, -0.020269403, -0.0022983477, 0.0...  \n",
       "522  [-0.023337308, -0.021497937, 0.1249926, -0.014...  \n",
       "523  [-0.020676365, -0.031019937, 0.101447135, 0.03...  \n",
       "526  [-0.07356925, -0.06716579, 0.0592213, 0.053288...  \n",
       "528  [0.014884363, 0.018558545, 0.037044585, 0.0125...  \n",
       "531  [-0.035937082, 0.032252643, 0.039746188, 0.013...  \n",
       "533  [-0.019787563, -0.02365343, 0.11032831, -0.043...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['artist', 'preprocessed_lyrics', 'embeddings']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_lyrics_sentence_transformer(query, df, model):\n",
    "    # Encode the query to get the embedding\n",
    "    query_embedding = model.encode([query])[0]  \n",
    "    # Calculate cosine similarities between the query and all lyrics embeddings\n",
    "    similarities = cosine_similarity([query_embedding], df['embeddings'].tolist()).flatten()\n",
    "    # Get indices of the songs with the highest similarity scores\n",
    "    top_indices = similarities.argsort()[-5:][::-1]\n",
    "    return df.iloc[top_indices]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81e93db8b599470dbc317d6f910e993a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            artist                               title release_date\n",
      "3412  Taylor Swift               You Need To Calm Down   2019-06-14\n",
      "603   Charlie Puth       Haters Follow Me Like Twitter   2011-01-01\n",
      "3428  Taylor Swift                            Gorgeous   2017-10-20\n",
      "3628  Taylor Swift   The Making Of A Song - â€˜Gorgeousâ€™   2017-11-01\n",
      "2335    Katy Perry  Hot N Cold (Innerpartysystem Main)   2008-11-24\n"
     ]
    }
   ],
   "source": [
    "query = \"you are somebody that i don't know but you're takin' shots at me like it's patrÃ³n\"\n",
    "results = search_lyrics_sentence_transformer(query, df, model)\n",
    "print(results[['artist', 'title', 'release_date']])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
